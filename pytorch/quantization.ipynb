{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating-point model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M(\n",
       "  (quant): QuantStub()\n",
       "  (conv1): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (conv2): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class M(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M, self).__init__()\n",
    "        # QuantStub converts tensors from floating point to quantized\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 1, 1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(1, 1, 1)\n",
    "        # DeQuantStub converts tensors from quantized to floating point\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # manually specify where tensors will be converted from floating\n",
    "        # point to quantized in the quantized model\n",
    "        x = self.quant(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        # manually specify where tensors will be converted from quantized\n",
    "        # to floating point in the quantized model\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "model_fp32 = M()\n",
    "model_fp32.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量化\n",
    "\n",
    "\"fbgemm\"对activation采用HistogramObserver，对weight采用PerChannelMinMaxObserver："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fp32.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "model_fp32.qconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "融合conv1 + relu："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/miniconda3/envs/base_3.8/lib/python3.8/site-packages/torch/ao/quantization/observer.py:172: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (conv1): ConvReLU2d(\n",
       "    (0): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (relu): Identity()\n",
       "  (conv2): Conv2d(\n",
       "    1, 1, kernel_size=(1, 1), stride=(1, 1)\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fp32_fused = torch.quantization.fuse_modules(model_fp32, [['conv1', 'relu']])\n",
    "model_fp32_prepared = torch.quantization.prepare(model_fp32_fused)\n",
    "model_fp32_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 校准模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/miniconda3/envs/base_3.8/lib/python3.8/site-packages/torch/ao/quantization/observer.py:886: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_begin // dst_bin_width, 0, self.dst_nbins - 1\n",
      "/home/austin/miniconda3/envs/base_3.8/lib/python3.8/site-packages/torch/ao/quantization/observer.py:891: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_end // dst_bin_width, 0, self.dst_nbins - 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M(\n",
       "  (quant): Quantize(scale=tensor([0.0011]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (conv1): QuantizedConvReLU2d(1, 1, kernel_size=(1, 1), stride=(1, 1), scale=0.006616627331823111, zero_point=0)\n",
       "  (relu): Identity()\n",
       "  (conv2): QuantizedConv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), scale=0.012025130912661552, zero_point=0)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fp32 = torch.randn(1, 1, 2, 3)\n",
    "model_fp32_prepared(input_fp32)\n",
    "\n",
    "model_int8 = torch.quantization.convert(model_fp32_prepared)\n",
    "model_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比浮点和定点模型\n",
    "输出浮点模型和定点模型结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[1.2747, 1.3228, 1.3228],\n",
       "           [1.3228, 1.2747, 1.2747]]]]),\n",
       " tensor([[[[1.2804, 1.5274, 1.3441],\n",
       "           [1.3480, 1.1642, 1.2445]]]], grad_fn=<SlowConv2DBackward0>))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8(input_fp32), model_fp32(input_fp32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对比两个模型conv1的weight："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.3052]]]], size=(1, 1, 1, 1), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_channel_affine,\n",
      "       scale=tensor([0.0024], dtype=torch.float64), zero_point=tensor([0]),\n",
      "       axis=0)\n",
      "Parameter containing:\n",
      "tensor([[[[0.3064]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model_int8.conv1.weight())\n",
    "print(model_fp32.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_int8实际运行时其conv1的weight_int为`weight/scale`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[127]]]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "print(model_int8.conv1.weight().int_repr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_int8实际运行时送入conv1的数据为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0, 255, 255],\n",
       "          [255,   0,   0]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.quant(input_fp32).int_repr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qx反量化后为dqx，和input_fp32对比："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0000, 0.2748, 0.2748],\n",
       "           [0.2748, 0.0000, 0.0000]]]]),\n",
       " tensor([[[[-0.0087,  1.4414,  0.3655],\n",
       "           [ 0.3885, -0.6908, -0.2191]]]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qx = model_int8.quant(input_fp32)\n",
    "dqx = torch.dequantize(qx)\n",
    "dqx, input_fp32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建一个伪定点模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M(\n",
       "  (quant): QuantStub()\n",
       "  (conv1): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (conv2): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "fake_qmodel = deepcopy(model_fp32)\n",
    "fake_qmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "替换conv1.weight为model_int8.conv1.weight的反量化值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[0.3052]]]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq_weight = torch.dequantize(model_int8.conv1.weight())\n",
    "fake_qmodel.conv1.weight = torch.nn.Parameter(dq_weight)\n",
    "fake_qmodel.conv1.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对比三个模型conv1的weight："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_int8: tensor([[[[0.3052]]]], size=(1, 1, 1, 1), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_channel_affine,\n",
      "       scale=tensor([0.0024], dtype=torch.float64), zero_point=tensor([0]),\n",
      "       axis=0)\n",
      "\n",
      "model_fp32: Parameter containing:\n",
      "tensor([[[[0.3064]]]], requires_grad=True)\n",
      "\n",
      "fake_qmodel: Parameter containing:\n",
      "tensor([[[[0.3052]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('model_int8:', model_int8.conv1.weight())\n",
    "print('\\nmodel_fp32:', model_fp32.conv1.weight)\n",
    "print('\\nfake_qmodel:', fake_qmodel.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面对比fake_qmodel.conv1和model_int8.conv1的结果，注意：\n",
    "1. qx（torch.quint8）和dqx（torch.float）的值是一样的，只是类型不同\n",
    "2. 由于model_int8的conv1融合了relu，因此我们也对fake_qmodel.conv1输出结果加上F.relu："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.5894, 0.6733, 0.6733],\n",
       "           [0.6733, 0.5894, 0.5894]]]], grad_fn=<ReluBackward0>),\n",
       " tensor([[[[0.5889, 0.6749, 0.6749],\n",
       "           [0.6749, 0.5889, 0.5889]]]], size=(1, 1, 2, 3), dtype=torch.quint8,\n",
       "        quantization_scheme=torch.per_tensor_affine, scale=0.006616627331823111,\n",
       "        zero_point=0))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "F.relu(fake_qmodel.conv1(dqx)), model_int8.conv1(qx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从结果可以看出，虽然输入（qx、dqx）和conv1.weight的值都一样，但是结果仍然有差异，**这是应为model_int8.conv1计算时，用的是weight.int_repr()和qx.int_repr()做卷积，中间结果用int型保存，只是在输出时除以了浮点数scale**，而fake_qmodel.conv1始终以浮点数计算。\n",
    "\n",
    "为了验证这个结论，我们可以构造一个全定点模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全定点计算模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[[[127]]]], dtype=torch.int32),\n",
       " tensor([[[[  0, 255, 255],\n",
       "           [255,   0,   0]]]], dtype=torch.int32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_qmodel = deepcopy(model_fp32)\n",
    "full_qmodel.conv1.weight = torch.nn.Parameter(model_int8.conv1.weight().int_repr().int(), requires_grad=False)\n",
    "int_x = qx.int_repr().int()\n",
    "\n",
    "full_qmodel.conv1.weight, int_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了计算方便，将conv1.bias设为0："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0], dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_qmodel.conv1.bias = torch.nn.Parameter(torch.tensor([0], dtype=torch.int), requires_grad=False)\n",
    "full_qmodel.conv1.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准卷积计算公式：\n",
    "\n",
    "$Y = XW + B$\n",
    "\n",
    "由于将conv1.bias设为了0，那么量化后的卷积公式为：\n",
    "\n",
    "$Y_q = (\\frac{X}{s_x} + z)\\cdot \\frac{W}{s_w}$\n",
    "\n",
    "$\\quad = \\frac{XW}{s_xs_w} + \\frac{zW}{s_w}$\n",
    "\n",
    "$Y \\approx s_xs_wY_q - s_xWz + B$\n",
    "\n",
    "> 实际运行时 $- s_xWz + B$ 可以提前计算出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5894, 0.6733, 0.6733],\n",
       "          [0.6733, 0.5894, 0.5894]]]], dtype=torch.float64,\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_q = full_qmodel.conv1(int_x)\n",
    "z = qx.q_zero_point()\n",
    "sw = model_int8.conv1.weight().q_per_channel_scales()\n",
    "sx = qx.q_scale()\n",
    "w = torch.dequantize(model_int8.conv1.weight())\n",
    "B = model_fp32.conv1.bias\n",
    "\n",
    "Y_a = Y_q * sw * sx - sx*w*z + B\n",
    "F.relu(Y_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时结果和model_int8.conv1(qx)还是有差异："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.5889, 0.6749, 0.6749],\n",
       "           [0.6749, 0.5889, 0.5889]]]], size=(1, 1, 2, 3), dtype=torch.quint8,\n",
       "        quantization_scheme=torch.per_tensor_affine, scale=0.006616627331823111,\n",
       "        zero_point=0),\n",
       " tensor([[[[ 89, 102, 102],\n",
       "           [102,  89,  89]]]], dtype=torch.uint8))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.conv1(qx), model_int8.conv1(qx).int_repr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是因为model_int8.conv1在输出时又进行了一次量化，我们需要进行一次伪量化：\n",
    "\n",
    "$\\text{round}(\\frac{Y}{s_a})s_a = \\text{round}(\\frac{s_xs_w}{s_a}Y_q + \\frac{B}{s_a}) \\cdot s_a$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5889, 0.6749, 0.6749],\n",
       "          [0.6749, 0.5889, 0.5889]]]], dtype=torch.float64,\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_scale = model_int8.conv1.scale\n",
    "torch.round(Y_a / out_scale) * out_scale"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a3057a8c36782cd4f6331a3ae51fc068edd966d636a8a359d99ae7e41376aa0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base_3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
