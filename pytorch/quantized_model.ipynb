{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModule(\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       "  (fc): Linear(in_features=4, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        self.fc = torch.nn.Linear(4, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        print('qx:', x)\n",
    "        x = self.fc(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "model = MyModule()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qx: Proxy(x)\n",
      "MyModule(\n",
      "  (fc): Linear(in_features=4, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    fc = self.fc(x);  x = None\n",
      "    return fc\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from torch.fx import symbolic_trace\n",
    "\n",
    "symbolic_traced: torch.fx.GraphModule = symbolic_trace(model)\n",
    "print(symbolic_traced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quantize_model(model, inp):\n",
    "    model.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "    torch.quantization.prepare(model, inplace=True)\n",
    "    # Calibration\n",
    "    model(inp)\n",
    "    torch.quantization.convert(model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/miniconda3/envs/base_3.8/lib/python3.8/site-packages/torch/ao/quantization/observer.py:172: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/home/austin/miniconda3/envs/base_3.8/lib/python3.8/site-packages/torch/ao/quantization/observer.py:886: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_begin // dst_bin_width, 0, self.dst_nbins - 1\n",
      "/home/austin/miniconda3/envs/base_3.8/lib/python3.8/site-packages/torch/ao/quantization/observer.py:891: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_end // dst_bin_width, 0, self.dst_nbins - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qx: tensor([[-1.0000e+02,  0.0000e+00,  1.0000e-01,  1.0000e+03]])\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "inp = torch.tensor([[-100, 0, 0.1, 1000]], dtype=torch.float)\n",
    "\n",
    "qmodel = deepcopy(model)\n",
    "qmodel.eval()\n",
    "quantize_model(qmodel, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qx: Proxy(quant)\n",
      "MyModule(\n",
      "  (quant): Quantize(scale=tensor([8.6572]), zero_point=tensor([12]), dtype=torch.quint8)\n",
      "  (fc): QuantizedLinear(in_features=4, out_features=5, scale=3.0581657886505127, zero_point=0, qscheme=torch.per_channel_affine)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    quant = self.quant(x);  x = None\n",
      "    fc = self.fc(quant);  quant = None\n",
      "    dequant = self.dequant(fc);  fc = None\n",
      "    return dequant\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "symbolic_traced: torch.fx.GraphModule = symbolic_trace(qmodel)\n",
    "print(symbolic_traced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取模型的所有的nodes："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qx: Proxy(quant)\n",
      "qx: Proxy(quant)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['x', 'quant', 'fc', 'dequant']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "\n",
    "train_nodes, eval_nodes = get_graph_node_names(qmodel)\n",
    "eval_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果显示多了\"quant\"和\"dequant\"两个node。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qx: Proxy(quant)\n",
      "qx: Proxy(quant)\n",
      "x tensor([[-1.0000e+02,  0.0000e+00,  1.0000e-01,  1.0000e+03]])\n",
      "fc tensor([[  9.1745, 391.4452, 223.2461, 232.4206, 461.7830]], size=(1, 5),\n",
      "       dtype=torch.quint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=3.0581657886505127, zero_point=0)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "\n",
    "# 定义输出node\n",
    "return_nodes = {\n",
    "    'x': 'x',\n",
    "    'fc': 'fc',\n",
    "}\n",
    "\n",
    "# 进行重建\n",
    "n_model = create_feature_extractor(qmodel, return_nodes)\n",
    "\n",
    "out = n_model(inp)\n",
    "for k, v in out.items():\n",
    "    print(k, v) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model中的qx没有任何改变，但是qmodel中的qx被quantize了:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:\n",
      "qx: tensor([[-1.0000e+02,  0.0000e+00,  1.0000e-01,  1.0000e+03]])\n",
      "tensor([[  9.3630, 387.9530, 220.9602, 228.7354, 461.4546]]) \n",
      "\n",
      "qmodel:\n",
      "qx: tensor([[-103.8863,    0.0000,    0.0000, 1004.2339]], size=(1, 4),\n",
      "       dtype=torch.quint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=8.657188415527344, zero_point=12)\n",
      "tensor([[  9.1745, 391.4452, 223.2461, 232.4206, 461.7830]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print('model:')\n",
    "    print(model(inp), '\\n')\n",
    "\n",
    "print('qmodel:')\n",
    "print(qmodel(inp))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a3057a8c36782cd4f6331a3ae51fc068edd966d636a8a359d99ae7e41376aa0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base_3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
