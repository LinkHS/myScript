{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantWrapper(\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       "  (module): MyModule(\n",
       "    (conv): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self, ic, oc, kernel_size):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ic, oc, kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "model = MyModule(1, 1, 1)\n",
    "model = torch.quantization.QuantWrapper(model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qx: Proxy(x)\n",
      "MyModule(\n",
      "  (fc): Linear(in_features=4, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    fc = self.fc(x);  x = None\n",
      "    return fc\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from torch.fx import symbolic_trace\n",
    "\n",
    "symbolic_traced: torch.fx.GraphModule = symbolic_trace(model)\n",
    "print(symbolic_traced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_model(model, inp):\n",
    "    model.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "    torch.quantization.prepare(model, inplace=True)\n",
    "    # Calibration\n",
    "    model(inp)\n",
    "    torch.quantization.convert(model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/miniconda3/envs/base_3.8/lib/python3.8/site-packages/torch/ao/quantization/observer.py:172: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/home/austin/miniconda3/envs/base_3.8/lib/python3.8/site-packages/torch/ao/quantization/observer.py:886: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_begin // dst_bin_width, 0, self.dst_nbins - 1\n",
      "/home/austin/miniconda3/envs/base_3.8/lib/python3.8/site-packages/torch/ao/quantization/observer.py:891: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_end // dst_bin_width, 0, self.dst_nbins - 1\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "inp = torch.randn((1, 1, 3, 3))\n",
    "\n",
    "qmodel = deepcopy(model).eval()\n",
    "quantize_model(qmodel, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qx: Proxy(quant)\n",
      "MyModule(\n",
      "  (quant): Quantize(scale=tensor([8.6572]), zero_point=tensor([12]), dtype=torch.quint8)\n",
      "  (fc): QuantizedLinear(in_features=4, out_features=5, scale=5.336332321166992, zero_point=58, qscheme=torch.per_channel_affine)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    quant = self.quant(x);  x = None\n",
      "    fc = self.fc(quant);  quant = None\n",
      "    dequant = self.dequant(fc);  fc = None\n",
      "    return dequant\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "symbolic_traced: torch.fx.GraphModule = symbolic_trace(qmodel)\n",
    "print(symbolic_traced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取模型的所有的nodes："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qx: Proxy(quant)\n",
      "qx: Proxy(quant)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['x', 'quant', 'fc', 'dequant']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "\n",
    "train_nodes, eval_nodes = get_graph_node_names(qmodel)\n",
    "eval_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果显示多了\"quant\"和\"dequant\"两个node。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qx: Proxy(quant)\n",
      "qx: Proxy(quant)\n",
      "x tensor([[-1.0000e+02,  0.0000e+00,  1.0000e-01,  1.0000e+03]])\n",
      "fc tensor([[ 373.5433, -309.5073, -309.5073,  304.1709,  101.3903]], size=(1, 5),\n",
      "       dtype=torch.quint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=5.336332321166992, zero_point=58)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "\n",
    "# 定义输出node\n",
    "return_nodes = {\n",
    "    'x': 'x',\n",
    "    'fc': 'fc',\n",
    "}\n",
    "\n",
    "# 进行重建\n",
    "n_model = create_feature_extractor(qmodel, return_nodes)\n",
    "\n",
    "out = n_model(inp)\n",
    "for k, v in out.items():\n",
    "    print(k, v) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model中的qx没有任何改变，但是qmodel中的qx被quantize了:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:\n",
      "qx: tensor([[-1.0000e+02,  0.0000e+00,  1.0000e-01,  1.0000e+03]])\n",
      "tensor([[ 369.9384, -420.0211, -307.6655,  301.7999,  105.8759]]) \n",
      "\n",
      "qmodel:\n",
      "qx: tensor([[-103.8863,    0.0000,    0.0000, 1004.2339]], size=(1, 4),\n",
      "       dtype=torch.quint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=8.657188415527344, zero_point=12)\n",
      "tensor([[ 373.5433, -309.5073, -309.5073,  304.1709,  101.3903]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print('model:')\n",
    "    print(model(inp), '\\n')\n",
    "\n",
    "print('qmodel:')\n",
    "print(qmodel(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本知识\n",
    "$$\n",
    "Q(x, \\text{scale}, \\text{zero\\_point}) = \\text{round}(\\frac{x}{\\text{scale}} + \\text{zero\\_point})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面操作等价于：\n",
    "$\\text{round}(a / 1.6) \\times 1.6 = 3.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2000, size=(), dtype=torch.qint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=1.6, zero_point=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(3.0)\n",
    "qa = torch.quantize_per_tensor(a, 1.6, 0, torch.qint8)\n",
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2, dtype=torch.int8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7., size=(), dtype=torch.qint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=1.0, zero_point=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.quantized import QFunctional\n",
    "\n",
    "q_add = QFunctional()\n",
    "qa = torch.quantize_per_tensor(torch.tensor(3.0), 1.0, 0, torch.qint8)\n",
    "qb = torch.quantize_per_tensor(torch.tensor(4.0), 1.0, 0, torch.qint8)\n",
    "q_add.add(qa, qb)  # Equivalent to ``torch.ops.quantized.add(a, b, 1.0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedConv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "m = nn.quantized.Conv2d(1, 1, 1)\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a3057a8c36782cd4f6331a3ae51fc068edd966d636a8a359d99ae7e41376aa0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base_3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
