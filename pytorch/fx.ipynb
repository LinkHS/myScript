{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方示例库：https://github.dev/pytorch/examples/tree/main/fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## symbolic_trace和graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [#users=1] = placeholder[target=x]\n",
      "    %linear : [#users=1] = call_module[target=linear](args = (%x,), kwargs = {})\n",
      "    %clamp : [#users=1] = call_method[target=clamp](args = (%linear,), kwargs = {min: 0.0, max: 1.0})\n",
      "    return clamp\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.fx import symbolic_trace\n",
    "\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(4, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x).clamp(min=0.0, max=1.0)\n",
    "\n",
    "model = MyModule()\n",
    "\n",
    "# Symbolic tracing frontend - captures the semantics of the module\n",
    "symbolic_traced : torch.fx.GraphModule = symbolic_trace(model)\n",
    "\n",
    "# High-level intermediate representation (IR) - Graph representation\n",
    "print(symbolic_traced.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModule(\n",
      "  (linear): Linear(in_features=4, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    linear = self.linear(x);  x = None\n",
      "    clamp = linear.clamp(min = 0.0, max = 1.0);  linear = None\n",
      "    return clamp\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(symbolic_traced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode       name    target    args       kwargs\n",
      "-----------  ------  --------  ---------  ------------------------\n",
      "placeholder  x       x         ()         {}\n",
      "call_module  linear  linear    (x,)       {}\n",
      "call_method  clamp   clamp     (linear,)  {'min': 0.0, 'max': 1.0}\n",
      "output       output  output    (clamp,)   {}\n"
     ]
    }
   ],
   "source": [
    "#[[n.op, n.name, n.target, n.args, n.kwargs] for n in self.nodes]\n",
    "symbolic_traced.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garph Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Graph Manipulation\n",
    "\n",
    "E.g., Replace `torch.add()` calls with `torch.mul()` calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [#users=1] = placeholder[target=x]\n",
      "    %y : [#users=1] = placeholder[target=y]\n",
      "    %add : [#users=1] = call_function[target=torch.add](args = (%x, %y), kwargs = {})\n",
      "    return add\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import fx\n",
    "\n",
    "class M(torch.nn.Module):\n",
    "    def forward(self, x, y):\n",
    "        return torch.add(x, y)\n",
    "\n",
    "m_add = M()\n",
    "print(fx.Tracer().trace(m_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意判断的是`node.target`而非`node`，这样只需要替换`node.target`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule()\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x, y):\n",
      "    add = torch.mul(x, y);  x = y = None\n",
      "    return add\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def transform(m, tracer_class=fx.Tracer) -> torch.nn.Module:\n",
    "    graph: fx.Graph = tracer_class().trace(m)\n",
    "    for node in graph.nodes:\n",
    "        if node.op == 'call_function':\n",
    "            if node.target == torch.add:\n",
    "                node.target = torch.mul\n",
    "    graph.lint() # Does some checks to make sure the Graph is well-formed.\n",
    "    return fx.GraphModule(m, graph)\n",
    "\n",
    "m_mul = transform(m_add)\n",
    "print(m_mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g., Graph rewrites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M(torch.nn.Module):\n",
    "    def forward(self, x, y):\n",
    "        x = torch.add(x, y)\n",
    "        x1 = torch.mul(x, 3)\n",
    "        x2 = torch.mul(x, 2)\n",
    "        return x1 * x2\n",
    "\n",
    "m = M()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在`torch.add`后面插入`torch.relu`，注意使用`deepcopy(node)`防止被`replace_all_uses_with()`替换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M()\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x, y):\n",
      "    add = torch.add(x, y);  x = y = None\n",
      "    relu = torch.relu(add);  add = None\n",
      "    mul = torch.mul(relu, 3)\n",
      "    mul_1 = torch.mul(relu, 2);  relu = None\n",
      "    mul_2 = mul * mul_1;  mul = mul_1 = None\n",
      "    return mul_2\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "m_trace = fx.symbolic_trace(m)\n",
    "for node in m_trace.graph.nodes:\n",
    "    if (node.op, node.target) == (\"call_function\", torch.add):\n",
    "        with m_trace.graph.inserting_after(node):\n",
    "            # Insert a new `call_function` node calling `torch.relu`\n",
    "            new_node = m_trace.graph.call_function(torch.relu, args=(deepcopy(node),))\n",
    "            node.replace_all_uses_with(new_node)\n",
    "m_trace.recompile()\n",
    "print(m_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subgraph Rewriting With `replace_pattern()`\n",
    "\n",
    "更多内容和示例参见[官网](https://pytorch.org/docs/stable/fx.html#subgraph-rewriting-with-replace-pattern)，包括：\n",
    "- Replace one op\n",
    "- Conv/Batch Norm fusion\n",
    "- replace_pattern: Basic usage\n",
    "- Quantization\n",
    "- Invert Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proxy/Retracing\n",
    "\n",
    "E.g., Create a Graph Using Proxy Objects Instead of Tracing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule()\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x, y):\n",
      "    cat = torch.cat([x, y]);  x = y = None\n",
      "    tanh = torch.tanh(cat);  cat = None\n",
      "    neg = torch.neg(tanh)\n",
      "    add = torch.add(tanh, neg);  tanh = None\n",
      "    return neg\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.fx import Proxy, Graph, GraphModule\n",
    "\n",
    "# Create a graph independently of symbolic tracing\n",
    "graph = Graph()\n",
    "tracer = torch.fx.proxy.GraphAppendingTracer(graph)\n",
    "\n",
    "# Create raw Nodes\n",
    "raw1 = graph.placeholder('x')\n",
    "raw2 = graph.placeholder('y')\n",
    "\n",
    "# Initialize Proxies using the raw Nodes and graph's default tracer\n",
    "y = Proxy(raw1, tracer)\n",
    "z = Proxy(raw2, tracer)\n",
    "\n",
    "# Create other operations using the Proxies `y` and `z`\n",
    "a = torch.cat([y, z])\n",
    "b = torch.tanh(a)\n",
    "c = torch.neg(b)\n",
    "d = torch.add(b, c)\n",
    "\n",
    "# Create a new output Node and add it to the Graph.\n",
    "graph.output(c.node)\n",
    "\n",
    "# Wrap our created Graph in a GraphModule to get a final, runnable `nn.Module` instance\n",
    "mod = GraphModule(torch.nn.Module(), graph)\n",
    "\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g., Decomposing ReLU into its mathematical definition.\n",
    "\n",
    "Decompose model into smaller constituent operations. \n",
    " \n",
    "Here, we decompose `ReLU` into its mathematical definition: `(x > 0) * x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class M(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = torch.add(x, 2)\n",
    "        return torch.relu(x)\n",
    "\n",
    "m = M()\n",
    "\n",
    "inp = torch.tensor([2])\n",
    "m(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_relu: Proxy(add)\n",
      "GraphModule()\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    add = torch.add(x, 2);  x = None\n",
      "    gt = add > 0\n",
      "    mul = gt * add;  gt = add = None\n",
      "    return mul\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from torch.fx import map_arg\n",
    "\n",
    "def relu_decomposition(x):\n",
    "    print('my_relu:', x)\n",
    "    return (x > 0) * x\n",
    "\n",
    "decomposition_rules = {}\n",
    "decomposition_rules[torch.relu] = relu_decomposition\n",
    "\n",
    "def decompose(model: torch.nn.Module,\n",
    "              tracer_class : type = fx.Tracer) -> torch.nn.Module:\n",
    "    graph : fx.Graph = tracer_class().trace(model)\n",
    "    new_graph = fx.Graph()\n",
    "    env = {}\n",
    "    tracer = torch.fx.proxy.GraphAppendingTracer(graph)\n",
    "    for node in graph.nodes:\n",
    "        if node.op == 'call_function' and node.target in decomposition_rules:\n",
    "            # By wrapping the arguments with proxies, we can dispatch to the appropriate\n",
    "            # decomposition rule and implicitly add it to the Graph by symbolically tracing it.\n",
    "            proxy_args = map_arg(node.args, lambda n: fx.Proxy(env[n.name]))\n",
    "            output_proxy = decomposition_rules[node.target](*proxy_args)\n",
    "\n",
    "            new_node = output_proxy.node\n",
    "            env[node.name] = new_node\n",
    "        else:\n",
    "            # Default case: we don't have a decomposition rule for this\n",
    "            # node, so just copy the node over into the new graph.\n",
    "            new_node = new_graph.node_copy(node, lambda x: env[x.name])\n",
    "            env[node.name] = new_node\n",
    "    return fx.GraphModule(model, new_graph)\n",
    "\n",
    "m_new = decompose(m)\n",
    "print(m_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`print('my_relu:', x)`居然在这里打印了出来，其中参数`x`变为了上一个node也就是add，实际`forward()`时候没有执行`print()`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_new(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Interpreter Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E.g., [Shape Propagation](https://github.com/pytorch/pytorch/blob/master/torch/fx/passes/shape_prop.py)\n",
    "\n",
    "实现一个简单的Shape Propagation：\n",
    "> 这里代码有点问题，当`result != torch.Tensor`时，需要进一步处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.fx\n",
    "from torch.fx.node import Node\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "class ShapeProp:\n",
    "    def __init__(self, mod):\n",
    "        self.mod = mod\n",
    "        self.graph = mod.graph\n",
    "        self.modules = dict(self.mod.named_modules())\n",
    "\n",
    "    def propagate(self, *args):\n",
    "        args_iter = iter(args)\n",
    "        env : Dict[str, Node] = {}\n",
    "\n",
    "        def load_arg(a):\n",
    "            return torch.fx.graph.map_arg(a, lambda n: env[n.name])\n",
    "\n",
    "        def fetch_attr(target : str):\n",
    "            target_atoms = target.split('.')\n",
    "            attr_itr = self.mod\n",
    "            for i, atom in enumerate(target_atoms):\n",
    "                if not hasattr(attr_itr, atom):\n",
    "                    raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "                attr_itr = getattr(attr_itr, atom)\n",
    "            return attr_itr\n",
    "\n",
    "        for node in self.graph.nodes:\n",
    "            if node.op == 'placeholder':\n",
    "                result = next(args_iter)\n",
    "            elif node.op == 'get_attr':\n",
    "                result = fetch_attr(node.target)\n",
    "            elif node.op == 'call_function':\n",
    "                result = node.target(*load_arg(node.args), **load_arg(node.kwargs))\n",
    "            elif node.op == 'call_method':\n",
    "                self_obj, *args = load_arg(node.args)\n",
    "                kwargs = load_arg(node.kwargs)\n",
    "                result = getattr(self_obj, node.target)(*args, **kwargs)\n",
    "            elif node.op == 'call_module':\n",
    "                result = self.modules[node.target](*load_arg(node.args), **load_arg(node.kwargs))\n",
    "\n",
    "            # This is the only code specific to shape propagation.\n",
    "            # you can delete this `if` branch and this becomes\n",
    "            # a generic GraphModule interpreter.\n",
    "            if isinstance(result, torch.Tensor):\n",
    "                node.shape = result.shape\n",
    "                node.dtype = result.dtype\n",
    "            # else:\n",
    "            #     ......\n",
    "\n",
    "            env[node.name] = result\n",
    "\n",
    "        for node in self.graph.nodes:\n",
    "            print(node.name, node.shape, node.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([4]) torch.float32\n",
      "linear torch.Size([5]) torch.float32\n",
      "clamp torch.Size([5]) torch.float32\n",
      "output torch.Size([5]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "from torch.fx import symbolic_trace\n",
    "\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(4, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x).clamp(min=0.0, max=1.0)\n",
    "\n",
    "m = MyModule()\n",
    "traced_m = symbolic_trace(m)\n",
    "s = ShapeProp(traced_m)\n",
    "s.propagate(torch.randn(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch提供了[`class ShapeProp(torch.fx.Interpreter)`](https://github.com/pytorch/pytorch/blob/master/torch/fx/passes/shape_prop.py)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.float32 torch.Size([4])\n",
      "linear torch.float32 torch.Size([5])\n",
      "clamp torch.float32 torch.Size([5])\n",
      "output torch.float32 torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "from torch.fx.passes.shape_prop import ShapeProp\n",
    "\n",
    "ShapeProp(traced_m).propagate(torch.randn(4))\n",
    "for node in traced_m.graph.nodes:\n",
    "    print(node.name, node.meta['tensor_meta'].dtype,\n",
    "        node.meta['tensor_meta'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [fx.Interpreter](https://github.com/pytorch/pytorch/blob/master/torch/fx/interpreter.py)\n",
    "\n",
    "```\n",
    "run()\n",
    "    +-- run_node\n",
    "        +-- placeholder()\n",
    "        +-- get_attr()\n",
    "        +-- call_function()\n",
    "        +-- call_method()\n",
    "        +-- call_module()\n",
    "        +-- output()\n",
    "```\n",
    "\n",
    "交换`sigmoid()`和`neg()`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.fx.interpreter import Interpreter\n",
    "from typing import Tuple, Any\n",
    "from torch.fx.node import Target\n",
    "\n",
    "class NegSigmSwapInterpreter(Interpreter):\n",
    "    def call_function(self, target : Target,\n",
    "                      args : Tuple, kwargs : Dict) -> Any:\n",
    "        if target == torch.sigmoid:\n",
    "            return torch.neg(*args, **kwargs)\n",
    "\n",
    "    def call_method(self, target : Target,\n",
    "                    args : Tuple, kwargs : Dict) -> Any:\n",
    "        if target == 'neg':\n",
    "            call_self, *args_tail = args\n",
    "            return call_self.sigmoid(*args_tail, **kwargs)\n",
    "\n",
    "def fn(x):\n",
    "    return torch.sigmoid(x).neg()\n",
    "\n",
    "gm = torch.fx.symbolic_trace(fn)\n",
    "input = torch.randn(3, 4)\n",
    "result = NegSigmSwapInterpreter(gm).run(input)\n",
    "torch.testing.assert_allclose(result, torch.neg(input).sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature_extraction比如我们要提取ResNet模型的C4和C5特征： \n",
    "torch.fx还有一个比较实用的使用场景，那就是对模型进行特征提取，比如我们希望得到模型中间特征用来分析，或者用一些中间特征用于构建其它模型，比如检测和分割模型。比如我们要提取ResNet模型的C4和C5特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C4', torch.Size([1, 1024, 14, 14])), ('C5', torch.Size([1, 2048, 7, 7]))]\n"
     ]
    }
   ],
   "source": [
    "import torchvision, torch\n",
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "\n",
    "# 构建模型\n",
    "model = torchvision.models.resnet50()\n",
    "\n",
    "# 获取模型的所有的nodes\n",
    "train_nodes, eval_nodes = get_graph_node_names(model)\n",
    "\n",
    "# 定义输出node\n",
    "return_nodes = {'layer3.5.relu_2': 'C4', 'layer4.2.relu_2': 'C5'}\n",
    "\n",
    "# 进行重建\n",
    "n_model = create_feature_extractor(model, return_nodes)\n",
    "\n",
    "out = n_model(torch.rand(1, 3, 224, 224))\n",
    "print([(k, v.shape) for k, v in out.items()])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d77f13afa90975a0006858db988e82dc75484a4b1caaf9acd21bfd54c7be743"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
